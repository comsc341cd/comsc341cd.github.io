{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7992b6",
   "metadata": {},
   "source": [
    "(proj1_analysis)=\n",
    "# Project 1 Part 2: Analysis\n",
    "\n",
    ":::{epigraph}\n",
    "Randomized Experiments\n",
    "\n",
    "-- TODO your name here\n",
    ":::\n",
    "\n",
    ":::{admonition} Collaboration Statement\n",
    "- TODO brief statement on the nature of your collaboration.\n",
    "- TODO your collaborator's names here\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c21abc",
   "metadata": {},
   "source": [
    "## Part 2 Table of Contents and Rubric\n",
    "\n",
    "| Section | Points |\n",
    "|------------------------------------|-------|\n",
    "| [Causal question and study design: IHDP](causal-study-design-ihdp) | 2 |\n",
    "| [Estimation and interpretation: IHDP analysis](causal-estimation-and-interpretation-ihdp-analysis) | 2.5 |\n",
    "| [Reflection](reflection) | 0.5 |\n",
    "| Total | 5 pts |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb099480",
   "metadata": {},
   "source": [
    ":::{note} Grading guidelines\n",
    "\n",
    "The course projects offer an opportunity to practice the full causal inference workflow, from building estimators and formulating questions to conducting analyses and communicating your findings effectively. Here are some guidelines on how to approach the project:\n",
    "\n",
    "- For visualizations:\n",
    "    - Help your reader understand your findings through visually clear figures\n",
    "    - Label your axes, provide legends when appropriate, and add figure titles to provide context\n",
    "\n",
    "- For written responses:\n",
    "    - Support your ideas with specific evidence from your analysis or prior knowledge\n",
    "    - Write concisely but clearly -- one-word/one-phrase answers usually don't give enough space to show what you've learned\n",
    "\n",
    "If you're uncertain about any portion of the project, please do come to office hours, TA hours, or reach out on Ed! \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bca98a",
   "metadata": {},
   "source": [
    "# Notebook and function imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056663b",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "\n",
    "If you click on the vertical blue bar on the left of a cell, you can collapse the code which can help organize the notebook as you work through the project.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b3e6ca",
   "metadata": {},
   "source": [
    "If you have tested your implementation in Part 1 against the autograder, you would have generated a file called `proj1_functions.py`. Let's now import those functions into this notebook for use in Part 2. \n",
    "\n",
    "If you are running this notebook on the JupyterHub allocated for the course:\n",
    "\n",
    "1. Open the file browser by going to the menu bar \"View -> File Browser\"\n",
    "2. Navigate to `comsc341cd.github.io/projects/`, you should see your `proj1_analysis.ipynb` file in that folder\n",
    "3. Click on the upload button in the upper right and upload the `proj1_functions.py` file to this directory\n",
    "4. Run the following cell to import the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from proj1_functions import *\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98509fd4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07145f47",
   "metadata": {},
   "source": [
    "## 4. The Infant Health and Development Program\n",
    "\n",
    "Let's now dive into analyzing a real-world study: the Infant Health and Development Program (IHDP). The IHDP was a randomized experiment conducted in the 1980s to evaluate the effectiveness of an early intervention program for low-birthweight, prematurely born infants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ab9c2e",
   "metadata": {},
   "source": [
    "### 4.1 Prior Knowledge and Causal Question\n",
    "\n",
    "Read the following resources on the IHDP study:\n",
    "\n",
    "- [IHDP policy memo](https://policyforchildren.org/wp-content/uploads/2013/08/IHDP-Final-5.11.10.pdf)\n",
    "- [Brooks-Gunn et al. 1991](https://www.jpeds.com/article/S0022-3476(05)80896-0/pdf), pages 350-352\n",
    "\n",
    ":::{admonition} Content warning\n",
    ":class: warning\n",
    "\n",
    "The reading contains the term \"mental retardation,\" which was commonly used in medical and policy discussions at the time but is now outdated and harmful. Today, the term \"intellectual disability\" is preferred and is used medically and [federally](https://www.specialolympics.org/stories/news/rosas-law-signed-into-law-by-president-obama).\n",
    ":::\n",
    "\n",
    ":::{admonition} Reading Notes\n",
    ":class: note\n",
    "\n",
    "- The Brooks-Gunn et al. 1991 paper contains minute details about the study recruitment and data collection process. Don't worry about understanding every aspect of the study, but try to get a sense of the overall experimental design and the baseline characteristics reported in Table 1.\n",
    "\n",
    "- The original methods mention stratification by both birthweight and clinical site in the study design. Because the probability of treatment is the same for all stratified groups, both the stratified difference-in-means and unstratified difference-in-means are valid estimators. For the purposes of this project, we will analyze the efficiency of estimators that **post-stratify** by other covariates.\n",
    ":::\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. The outcome of interest we will be analyzing is the **Stanford-Binet Intelligence Scale score** (IQ) at an age of 36 months (3 years), and our causal quantity is the **average treatment effect (ATE)** on the child's IQ score. Describe what causal question we are trying to answer in this dataset in terms of the causal quantity we are trying to identify.\n",
    "\n",
    "2. State what $Y(1)$ and $Y(0)$ are in your own words given the treatment and outcome of the study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571f185",
   "metadata": {},
   "source": [
    "**TODO** your responses here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f99d6",
   "metadata": {},
   "source": [
    "### 4.2 Study Design\n",
    "\n",
    "Next, let's load the IHDP dataset and look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21d6704",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihdp_raw = pd.read_csv('~/COMSC-341CD/data/ihdp_real.csv')\n",
    "ihdp_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211dbdda",
   "metadata": {},
   "source": [
    "There are 50 total columns in the dataframe, but we will only use the following columns for the project:\n",
    "\n",
    "- `bw`: birth weight in grams\n",
    "- `momage`: mother's age in years\n",
    "- `nnhealth`: neonatal health index, higher scores indicate better health\n",
    "- `momwhite`: binary indicator for maternal ethnicity: 1 if white, 0 otherwise\n",
    "\n",
    "- `iqsb.36`: outcome: Stanford-Binet IQ score at 36 months\n",
    "- `treat`: binary treatment assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7d2a0a",
   "metadata": {},
   "source": [
    "Our study design is a randomized experiment, and we will assume that all of the assumptions that are needed to identify the average treatment effect hold. Answer the following questions:\n",
    "\n",
    "1. Suppose that our data did not come from a randomized experiment, and families were able to choose whether or not to participate in the intervention. Select two of the four variables listed above that you think may confound the relationship between the treatment and outcome, and explain why.\n",
    "\n",
    "**Your response:** TODO\n",
    "\n",
    "2. Given the two variables you selected in the previous question, treatment, and outcome, draw a DAG with these four variables if this data were not collected from a randomized experiment. Give each node a variable name (e.g. $T$, $Y$, $C_1$, $C_2$) and indicate what each variable represents.\n",
    "\n",
    "\n",
    "TODO draw your DAG\n",
    "\n",
    "3. Draw the modified DAG from the previous question under the scenario where the treatment is randomized.\n",
    "\n",
    "\n",
    "TODO draw your DAG\n",
    "\n",
    ":::{admonition} Submission note\n",
    ":class: tip\n",
    "\n",
    "For this question, you can either hand-draw the graphs on paper and submit a photo or use an online tool of your choice. Please make sure the image is submitted as a separate file on Gradescope.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616cd7a",
   "metadata": {},
   "source": [
    "### 4.3 Visualizing and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006db264",
   "metadata": {},
   "source": [
    "Let's next ensure that the baseline characteristics are balanced between the treatment and control groups. Complete the `baseline_stats` function below to verify that the `bw`, `momage`, `nnhealth`, and `momwhite` characteristics are balanced and roughly match the values reported in Table 1 of Brooks-Gunn et al 1991.\n",
    "\n",
    ":::{tip}\n",
    "\n",
    "- It is possible to complete this operation in one line by using pandas `groupby()` + `agg()`\n",
    "\n",
    "- Since `momwhite` is coded as a binary variable, the mean will be the proportion of `momwhite = 1` in the sample.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ad1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_stats(df, covariate):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation of a covariate \n",
    "    for the treatment and control groups.\n",
    "    Assumes that the treatment indicator column is named `treat`.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to compute the baseline stats\n",
    "        covariate (str): the name of the covariate to compute the baseline stats\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a grouped dataframe with the mean and standard deviation \n",
    "            of the covariate for the treatment and control groups\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    pass\n",
    "\n",
    "# display(baseline_stats(ihdp_raw, 'bw'))\n",
    "# display(baseline_stats(ihdp_raw, 'momage'))\n",
    "# display(baseline_stats(ihdp_raw, 'nnhealth'))\n",
    "# display(baseline_stats(ihdp_raw, 'momwhite'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cbbac0",
   "metadata": {},
   "source": [
    "Beyond having similar mean and standard deviation, an implication of exchangeability is that the treatment and control groups should have a similar *distribution* of covariates. We can inspect this by plotting the (cumulative) distribution of the covariates for the treatment and control groups and visually inspecting whether the two distributions are similar.\n",
    "\n",
    "Let's verify this is the case for our continuous variables `bw`, `momage`, and `nnhealth`, using a distribution plot via `sns.kdeplot`. Specfically, complete the `plot_covariate_distribution` function below by generating a kde plot with:\n",
    "\n",
    "- the covariate on the x-axis\n",
    "- `treat` as the hue\n",
    "- `ihdp_df` as the data\n",
    "- `common_norm=False` to ensure that the y-axis is on the same scale for both the treatment and control groups\n",
    "- **optional**: `cumulative=True` to plot the cumulative distribution, to make the curves easier to compare\n",
    "\n",
    ":::{note}\n",
    "For the statistically curious: a natural hypothesis to test here is whether the two datasets come from the same distribution, which can be done using a [two-sample Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fafce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covariate_distribution(df, covariate, title):\n",
    "    \"\"\"\n",
    "    Plots the (optionally cumulative) distribution of a covariate for the treatment and control groups.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to plot the covariate distribution\n",
    "        covariate (str): the name of the covariate to plot\n",
    "        title (str): the title of the plot\n",
    "    \n",
    "    Returns:\n",
    "        None, but shows the covariate distribution plot\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    plt.show()\n",
    "\n",
    "#plot_covariate_distribution(ihdp_raw, 'bw', 'TODO title')\n",
    "#plot_covariate_distribution(ihdp_raw, 'momage', 'TODO title')\n",
    "#plot_covariate_distribution(ihdp_raw, 'nnhealth', 'TODO title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcd28e8",
   "metadata": {},
   "source": [
    "Our outcome is `iqsb.36`, which are the infant's IQ score at 36 months. However, there are some missing values in the `iqsb.36` column, so we need to drop the rows that do not have the outcome. Update the `ihdp_clean` variable below to drop the rows that do not have the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f7d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here\n",
    "ihdp_clean = None\n",
    "assert ihdp_clean.shape[0] == ihdp_raw['iqsb.36'].notna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da85084f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee2b34f",
   "metadata": {},
   "source": [
    "## 5. Estimation and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425f2b5",
   "metadata": {},
   "source": [
    "### 5.1 Difference-in-means estimation\n",
    "\n",
    "We'll now want to apply our difference-in-means estimators to the IHDP dataset. In order to use our stratified difference-in-means estimator, we need to binarize the continuous covariates we are analyzing. \n",
    "\n",
    "Apply the `binarize_covariate` function implmemented in part 1 to the `momage` and `nnhealth` covariates:\n",
    "- using a cutpoint of 22 years for `momage`\n",
    "- using a cutpoint of 100 for `nnhealth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f430d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO call binarize_covariate on the `momage` and `nnhealth` covariates for ihdp_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f46477",
   "metadata": {},
   "source": [
    "Finally, let's compute our results. For the following difference-in-means estimators:\n",
    " - unstratified difference-in-means estimator for the `iqsb.36` outcome\n",
    " - stratified difference-in-means estimator for the `iqsb.36` outcome, binarized by `momage`\n",
    " - stratified difference-in-means estimator for the `iqsb.36` outcome, binarized by `nnhealth`\n",
    " - stratified difference-in-means estimator for the `iqsb.36` outcome, binarized by `momwhite`\n",
    "\n",
    "Compute and report the following in the markdown table below (up to two decimal places):\n",
    "- the estimate for the difference-in-means estimator, **using the cleaned dataset** (not a bootstrap sample).\n",
    "- the bootstrapped 95% confidence interval (CI) for the difference-in-means estimator\n",
    "- the length of the confidence interval, which is the difference between the upper and lower bounds of the confidence interval\n",
    "\n",
    ":::{tip}\n",
    "See the comments in the code cell below for guidance on how you might want to structure your analysis, and feel free to create helper functions to organize your code. You do not have to follow the comments exactly, they are just a suggestion!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566af867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get point estimates using the cleaned dataset\n",
    "point_estimates = {\n",
    "    \"unstratified\": 0,\n",
    "    \"stratified_nnhealth\": 0,\n",
    "    \"stratified_momage\": 0,\n",
    "    \"stratified_momwhite\": 0\n",
    "}\n",
    "\n",
    "# TODO generate bootstrap dataframes\n",
    "\n",
    "# TODO create a data structure to store difference-in-means results\n",
    "\n",
    "# TODO compute difference-in-means for each bootstrapped dataframe\n",
    "\n",
    "# TODO report the results for each estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ca2820",
   "metadata": {},
   "source": [
    "| Estimator | Effect | 95% CI | Length of CI |\n",
    "| --- | --- | --- | --- |\n",
    "| Difference-in-means | TODO | TODO | TODO |\n",
    "| Difference-in-means stratified by `nnhealth_bin` | TODO | TODO | TODO |\n",
    "| Difference-in-means stratified by `momage_bin` | TODO | TODO | TODO |\n",
    "| Difference-in-means stratified by `momwhite` | TODO | TODO | TODO |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0b36c8",
   "metadata": {},
   "source": [
    "### 5.2 Interpretation\n",
    "\n",
    "Finally, let's interpret the results.\n",
    "\n",
    "1. Do any of the estimators appear to disagree with the others in terms of the estimate? Which estimator produces the shortest confidence interval?\n",
    "\n",
    "2. Based on your analysis, what conclusions can you draw about the average treatment effect of the intervention? Does it improve or worsen the outcome? \n",
    "\n",
    "3. Discuss ethical/design considerations of the experimental setup you noticed along the three principles of the Belmont Report: 1 short paragraph (~2-4 sentences) per principle. You can refer back to our discussion of these challenges from class, and the study design described in the reading. Some questions you could (but don't have to) consider in your responses:\n",
    "\n",
    "    - At the time the study was designed, do you think there was genuine uncertainty about the effectiveness of the intervention? Why might researchers have considered the intervention promising but unproven?\n",
    "    - What do you notice about how infants were recruited into the study? Are they representative of the overall U.S. population of underweight newborns?\n",
    "    - Is the selected outcome appropriate for evaluating the intervention's impact? What are some other outcomes that could be used to evaluate the intervention?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df7305",
   "metadata": {},
   "source": [
    "## 6. Reflection\n",
    "\n",
    "1. How much time did you spend on this assignment?\n",
    "\n",
    "2. Were there any parts of the assignment that you found particularly challenging?\n",
    "\n",
    "3. What is one thing you have a better understanding of after completing this assignment and going through the class content?\n",
    "\n",
    "4. Do you have any follow-up questions about concepts that you'd like to explore further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263f734",
   "metadata": {},
   "source": [
    "**TODO** your responses here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715caf11",
   "metadata": {},
   "source": [
    "## 7. Optional extensions\n",
    "\n",
    "If you'd like, here are some optional extensions you can explore and implement:\n",
    "\n",
    "- Our stratified estimator currently only works for stratifying on binary variables. A natural extension would be to modify our `diff_in_means_stratified` function to work for multiple strata.\n",
    "- Once our stratified difference in means estimate is extended to support multiple strata, we can explore the trade-off between using more or fewer strata for continuous variables, and seeing how this affects the variance of our estimator. This can be done by using the `pd.cut` function to bin the covariate into a discrete number of bins.\n",
    "- Another benefit of a randomized experiment is that we can use them to study multiple outcomes. Brooks-Gunn et al. 1991 mention that the IQ score only provide a global estimate of cognitive function, and so also conduct analysis on the Peabody Picture Vocabulary Test (PPVT) which assesses vocabulary. We can follow the causal roadmap again to analyze this outcome, represented as the `ppvt.imp` column in the IHDP dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
