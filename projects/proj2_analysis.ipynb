{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(proj2_analysis)=\n",
    "# Project 2 Part 2: Analysis\n",
    "\n",
    ":::{epigraph}\n",
    "Observational Studies\n",
    "\n",
    "-- TODO your name here\n",
    ":::\n",
    "\n",
    ":::{admonition} Collaboration Statement\n",
    "- TODO brief statement on the nature of your collaboration.\n",
    "- TODO your collaborator's names here\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Part 2 Table of Contents and Rubric\n",
    "\n",
    "| Section | Points |\n",
    "|------------------------------------|-------|\n",
    "| Visualizing trimming effects | 1 |\n",
    "| Study design: Lalonde | 2 |\n",
    "| Estimation and interpretation: Lalonde | 1.5 |\n",
    "| Reflection | 0.5 |\n",
    "| Total | 5 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note} Grading guidelines\n",
    "\n",
    "The course projects offer an opportunity to practice the full causal inference workflow, from building estimators and formulating questions to conducting analyses and communicating your findings effectively. Here are some guidelines on how to approach the project:\n",
    "\n",
    "- For visualizations:\n",
    "    - Help your reader understand your findings through visually clear figures\n",
    "    - Label your axes, provide legends when appropriate, and add figure titles to provide context\n",
    "\n",
    "- For written responses:\n",
    "    - Support your ideas with specific evidence from your analysis or prior knowledge\n",
    "    - Write concisely but clearly -- one-word/one-phrase answers usually don't give enough space to show what you've learned\n",
    "\n",
    "If you're uncertain about any portion of the project, please do come to office hours, TA hours, or reach out on Ed! \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook and function imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{tip}\n",
    "\n",
    "If you click on the vertical blue bar on the left of a cell, you can collapse the code which can help organize the notebook as you work through the project.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have tested your implementation in Part 1 against the autograder, you would have generated a file called `proj2_functions.py`. Let's now import those functions into this notebook for use in Part 2. \n",
    "\n",
    "If you are running this notebook on the JupyterHub allocated for the course:\n",
    "\n",
    "1. Open the file browser by going to the menu bar \"View -> File Browser\"\n",
    "2. Navigate to `comsc341cd.github.io/projects/`, you should see your `proj2_analysis.ipynb` file in that folder\n",
    "3. Click on the upload button in the upper right and upload the `proj2_functions.py` file to this directory\n",
    "4. Run the following cell to import the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from ipywidgets import interact_manual\n",
    "\n",
    "from proj2_functions import *\n",
    "\n",
    "rng = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have provided implementations of `bootstrap_ci` and `bootstrap_dfs` from Project 1, as well as `reg_diff_in_means` which uses linear regression to estimate difference-in-means below:\n",
    "\n",
    ":::{note}\n",
    "\n",
    "The fact that our matching estimator matches **without** replacment is critical for making our bootstrap confidence intervals valid. For the statistically curious, you can see [Austin and Small 2014: The use of bootstrapping when using propensity-score matching without replacement: a simulation study](https://pmc.ncbi.nlm.nih.gov/articles/PMC4260115/) for a detailed exploration of why.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_code",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def bootstrap_ci(bootstrap_values, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Computes the confidence interval using the percentile method.\n",
    "\n",
    "    Args:\n",
    "        bootstrap_values (list[float]): the bootstrapped values\n",
    "        alpha (float): the significance level, defaults to 0.05\n",
    "\n",
    "    Returns:\n",
    "        list[float]: the confidence interval [lower, upper]\n",
    "    \"\"\"\n",
    "    lower = np.percentile(bootstrap_values, alpha * 100)\n",
    "    upper = np.percentile(bootstrap_values, (1 - alpha) * 100)\n",
    "    return [lower, upper]\n",
    "\n",
    "\n",
    "def bootstrap_dfs(df, n_bootstraps=10000):\n",
    "    \"\"\"\n",
    "    Bootstraps the dataframe `n_bootstraps` times.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to bootstrap\n",
    "        n_bootstraps (int): the number of bootstraps to generate\n",
    "\n",
    "    Returns:\n",
    "        list[pd.DataFrame]: a list of bootstrapped dataframes\n",
    "    \"\"\"\n",
    "    bootstrap_dfs = []\n",
    "\n",
    "    for i in range(n_bootstraps):\n",
    "        bootstrap_dfs.append(df.sample(frac=1, replace=True))\n",
    "\n",
    "    return bootstrap_dfs\n",
    "\n",
    "\n",
    "def reg_diff_in_means(data, outcome_col, treat_col):\n",
    "    \"\"\"\n",
    "    Computes the difference in means between the treatment and control groups using a regression model.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): the dataframe containing the data\n",
    "        outcome_col (str): the name of the outcome variable\n",
    "        treat_col (str): the name of the treatment variable\n",
    "\n",
    "    Returns:\n",
    "        float: the difference in means between the treatment and control groups\n",
    "    \"\"\"\n",
    "    reg_result = smf.ols(f'{outcome_col} ~ 1 + {treat_col}', data=data).fit()\n",
    "    return reg_result.params[treat_col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also provided a helper function called `generate_estimates()` that will compute both the point estimate and bootstrapped confidence interval for any estimator function you pass to it. Read through the docstring and the code below to make sure you understand how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_code",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_estimates(data, estimator_func, treat_col, outcome_col, n_bootstraps=2000):\n",
    "    \"\"\"\n",
    "    Computes the point estimate the and bootstrapped 95% confidence interval for an estimator function.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): the dataframe containing the data\n",
    "        estimator_func (function): the estimator function to use\n",
    "        treat_col (str): the name of the treatment variable\n",
    "        outcome_col (str): the name of the outcome variable\n",
    "        n_bootstraps (int): the number of bootstraps to use\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary containing the point estimate, bootstrapped confidence interval, and bootstrapped values\n",
    "    \"\"\"\n",
    "    # compute the point estimate\n",
    "    point_estimate = estimator_func(data, treat_col=treat_col, outcome_col=outcome_col)\n",
    "    \n",
    "    # generate the bootstrap samples\n",
    "    bootstrap_samples = bootstrap_dfs(data, n_bootstraps)\n",
    "    # compute the bootstrap estimates\n",
    "    bootstrap_values = []\n",
    "\n",
    "    for bootstrap_sample in bootstrap_samples:\n",
    "        bootstrap_values.append(estimator_func(bootstrap_sample, treat_col=treat_col, outcome_col=outcome_col))\n",
    "    \n",
    "    # compute the confidence interval, which is a list of two floats\n",
    "    ci = bootstrap_ci(bootstrap_values, alpha=0.05)\n",
    "    \n",
    "    return {'point_estimate': point_estimate, 'ci': ci, 'bootstrap_values': bootstrap_values}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we had a dataset `df` with treatment column `T` and outcome column `Y`, we could compute the point estimate and 95% confidence interval for the difference-in-means estimator as follows:\n",
    "\n",
    "```python\n",
    "diff_in_means_results = generate_estimates(data=df, estimator_func=reg_diff_in_means, treat_col='T', outcome_col='Y')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulation study: effects of trimming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a simulated observational study dataset in `~/COMSC-341CD/data/sim_observational_study.csv`, with a true ATT of 1, and the true propensity score given by the `propensity_score` column.\n",
    "\n",
    "Complete the widget below to explore the effect of trimming the propensity score on the balance and estimate distribution. The `plot_balance_and_estimate_distribution()` function will generate three plots on one row: \n",
    "\n",
    "- `axs[0]` will show the overlap in the propensity score distribution between the treated and control groups in the trimmed dataset\n",
    "- `axs[1]` will show the overlap in the propensity score distribution between the treated and control groups in the trimmed dataset after matching has been performed\n",
    "- `axs[2]` will show the distribution of the ATT estimate for the matched dataset, compared to the true ATT of 1\n",
    "\n",
    "Be sure to label the axes and add a title to each plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO add an interact_manual decorator for lower_bound and upper_bound, in increments of 0.1\n",
    "# @interact_manual(TODO)\n",
    "def plot_balance_and_estimate_distributions(lower_bound=0.0, upper_bound=1):\n",
    "    \"\"\"\n",
    "    Plots the trimmed distribution, matched distribution, and the ATT estimate distribution for a dataset given a lower and upper bound trimming of the propensity score.\n",
    "\n",
    "    Args:\n",
    "        lower_bound (float): the lower bound of the propensity score\n",
    "        upper_bound (float): the upper bound of the propensity score\n",
    "    \"\"\"\n",
    "    assert lower_bound < upper_bound, \"Lower bound must be less than upper bound\"\n",
    "\n",
    "    # Load in the simulated dataset, note that is already has a 'propensity_score' column\n",
    "    data = pd.read_csv(\"~/COMSC-341CD/data/sim_observational_study.csv\")\n",
    "\n",
    "    # TODO trim the data_df with the lower and upper bounds\n",
    "    trimmed_df = None\n",
    "    # TODO match the trimmed dataset\n",
    "    matched_df = None\n",
    "    # TODO generate results for the matched dataset\n",
    "    matched_results = generate_estimates(data='TODO', estimator_func=reg_diff_in_means, treat_col='T', outcome_col='Y')\n",
    "\n",
    "    # generate 3 plots on one row\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    #### axs[0] ####\n",
    "    # TODO plot the propensity score distribution of trimmed_df on axs[0], where x='propensity_score' and hue='T'\n",
    "    # sns.kdeplot(TODO)\n",
    "\n",
    "    # fix the x-axis for easier comparison\n",
    "    axs[0].set_xlim(0, 1)\n",
    "\n",
    "\n",
    "    #### axs[1] ####\n",
    "    # TODO plot the propensity score distribution of matched_df on axs[1], where x='propensity_score' and hue='T'\n",
    "    # sns.kdeplot(TODO)\n",
    "\n",
    "    # fix the x-axis for easier comparison\n",
    "    axs[1].set_xlim(0, 1)\n",
    "\n",
    "\n",
    "    #### axs[2] ####\n",
    "    # TODO plot the ATT estimate distribution on axs[2] as a histogram, using matched_results['bootstrap_values']\n",
    "    # sns.histplot(TODO)\n",
    "\n",
    "    # TODO plot vertical lines for the estimated ATT using matched_results['point_estimate']\n",
    "\n",
    "    # TODO plot a vertical line for the true ATT, which is x=1\n",
    "\n",
    "    # fix the x-axis for easier comparison\n",
    "    axs[2].set_xlim(-1, 3)\n",
    "\n",
    "    fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "If the bounds are too narrow, the widget may throw an error due to no control units being found for some treated units during matching. That is to be expected, and does not indicate an issue with your code.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions based on the widget above:\n",
    "\n",
    "1.1. When there is no trimming (lower_bound = 0 and upper_bound = 1), what do you observe about the ATT estimate (right plot)? Does the estimated effect appear to be biased? Looking at the non-matched propensity score distribution (left plot), what do you observe about potential overlap concerns with the treated and control groups? \n",
    "\n",
    "1.2. Holding the upper bound constant at 1, what do you observe about the ATT distribution (right plot) and the matched propensity score distribution (middle plot) as you vary the lower bound?\n",
    "\n",
    "1.3. Holding the lower bound constant at 0, what do you observe about the ATT distribution (right plot) and the matched propensity score distribution (middle plot) as you vary the upper bound?\n",
    "\n",
    "1.4. Based on the matched propensity score distribution and the ATT distribution, what appears to be a reasonable upper and lower bound for trimming the propensity score? \n",
    "\n",
    "**TODO your responses below**:\n",
    "\n",
    "1.1.\n",
    "\n",
    "1.2.\n",
    "\n",
    "1.3. \n",
    "\n",
    "1.4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Lalonde Study\n",
    "\n",
    "[Lalonde (1986)](https://www.jstor.org/stable/1806062?seq=1) was a landmark study in causal inference, as it aimed to compare non-experimental observational methods of estimating causal effects to those from a randomized experiment. It analyzed data from the National Supported Work Demonstration (NSW) program, where participants across the United States were randomly assigned to the job-training program.\n",
    "\n",
    "## Prior Knowledge and Causal Question\n",
    "\n",
    "Below is a description of the NSW program adapted from [Cunninngham 2021](https://mixtape.scunning.com/) and [Manpower Demonstration Research Corporation 1983](https://www.mdrc.org/sites/default/files/full_249.pdf):\n",
    "\n",
    "> The National Supported Work Demonstration (NSW) job-training program was operated by the Manpower Demonstration Research Corp (MDRC) in the mid-1970s. The NSW was a temporary employment program designed to help individuals facing employment barriers develop basic job skills and transition into the labor market by providing work experience and counseling in a supportive environment. It was also unique in that it randomly assigned eligible applicants to training positions. The treatment group received all the benefits of the NSW program. The comparison group did not receive these benefits. The program served women receiving Aid to Families with Dependent Children, people in recovery from substance use disorders, formerly incarcerated individuals, and adults who had not completed high school. The sites were located in 15 different locations across the United States:\n",
    "\n",
    "<div style=\"max-width:500px; margin: auto;\"> \n",
    "\n",
    "![](../images/proj2_mdrc_locations.png)\n",
    "\n",
    "</div>\n",
    "\n",
    "> Treatment group participants were provided a job for nine to eighteen months depending on the target group and site. They were organized into crews of three to five participants who worked together and met frequently with an NSW counselor to discuss concerns about the program and performance. Additionally, they received compensation for their work. NSW offered the participants initial wages that were lower than standard employment rates, but included opportunities for earnings to increase based on satisfactory performance and attendance. After participants completed their terms, they needed to secure regular employment. The types of jobs varied within sites—some worked as gas-station attendants, some worked at a printer shop—and the work assignments often differed between men and women.\n",
    "\n",
    "The causal question of interest is whether the National Supported Work Demonstration program (NSW) deployed in 1976-77 had an effect on the participants' 1978 earnings, and the causal quantity that is targeted is the average treatment effect on the treated (ATT):\n",
    "\n",
    "$$\n",
    "ATT = \\mathbb{E}[Y(1) - Y(0) \\mid T = 1]\n",
    "$$\n",
    "\n",
    "- treatment $T$: whether the participant was in the NSW program\n",
    "- outcome $Y$: the participant's earnings in 1978\n",
    "\n",
    "Lalonde and subsequent researchers constructed two datasets: an experimental dataset where the treatment was randomly assigned, and an observational dataset built from other national survey data to serve as controls. We can therefore use the experimental dataset to estimate the causal effect of the treatment as the \"true\" ATT effect, and use it to compare the performance of our observational methods.\n",
    "\n",
    "In particular, there are the following variables in the dataset:\n",
    "\n",
    "- `re78`: **outcome**: the participant's **re**al (inflation-adjusted) earnings in 1978\n",
    "- `treat`: **treatment**: whether the participant was in the NSW program\n",
    "- `u74`: whether the participant was unemployed in 1974\n",
    "- `u75`: whether the participant was unemployed in 1975\n",
    "- `re74`: the participant's real earnings in 1974\n",
    "- `re75`: the participant's real earnings in 1975\n",
    "- `black`: whether the participant is black\n",
    "- `hisp`: whether the participant is Hispanic\n",
    "- `marr`: whether the participant is married\n",
    "- `nodegree`: whether the participant has a high school degree\n",
    "- `age`: the participant's age\n",
    "- `educ`: the participant's education level as a number of years of schooling (e.g. 12 for high school graudate, 16 for college graduate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design\n",
    "\n",
    "**Figure 1**: Load in the observational dataset and fit a propensity score model to assess positivity and overlap. Complete the code cell below to create two histogram plots side-by-side, where the left plot shows the overall shape of the propensity score distribution, and the right plot zooms in using [axes.set_ylim()](https://matplotlib.org/stable/api/_as_gen/matplotlib.axes.Axes.set_ylim.html) to get a better view of overlap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "observational_df = pd.read_csv('~/COMSC-341CD/data/nsw_observational.csv')\n",
    "covariates = ['age', 'educ', 'black', 'hisp', 'marr', 'nodegree', 're74', 're75', 'u74', 'u75']\n",
    "\n",
    "# TODO fit propensity score model and create the 'propensity_score' column\n",
    "\n",
    "# TODO plot two plots side-by-side, where the left plot shows the overall shape of the propensity score distribution, and the right plot zooms in using`ax.set_ylim()` to get a better view of overlap\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "fig.suptitle('Figure 1: Propensity Score Distribution')\n",
    "\n",
    "#### axs[0] ####\n",
    "# sns.histplot(data=TODO, \n",
    "#             x=TODO,\n",
    "#             hue=TODO,\n",
    "#             ax=TODO,\n",
    "#             bins=15, \n",
    "#             multiple='stack') # this stacks the histograms for easier comparison\n",
    "# axs[0].set_title(TODO)\n",
    "\n",
    "#### axs[1] ####\n",
    "# TODO repeat the same plot as above, but zoom in using set_ylim(0, 100) to get a better view of overlap\n",
    "\n",
    "# axs[1].set_ylim(0, 100)\n",
    "# axs[1].set_title(TODO)\n",
    "\n",
    "# save the figure for viewing later\n",
    "fig.savefig('fig1_propensity_score_distribution.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, trim the dataset using a lower bound of 0.1 and an upper bound of 1 and then **refit** the propensity score model for the trimmed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO trim the dataset using a lower bound of 0.1 and an upper bound of 1\n",
    "trimmed_df = None\n",
    "\n",
    "# TODO refit the propensity score model for the trimmed dataset and update the 'propensity_score' column\n",
    "# trimmed_df['propensity_score'] = TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 2**: Finally, generate two matched datasets: one using the observational dataset, and one using the trimmed dataset. Plot the Love plots for the two matched datasets side by side, fixing their x-axis limits to be the same for easier comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO generate the matched datasets\n",
    "# matched_df = TODO\n",
    "# matched_trimmed_df = TODO\n",
    "\n",
    "\n",
    "# TODO call std_diff_dataframe for the two matched datasets. \n",
    "# Be sure to pair matched_df with observational_df, and matched_trimmed_df with trimmed_df\n",
    "# observational_std_diff = TODO\n",
    "# trimmed_std_diff = TODO\n",
    "\n",
    "# TODO plot the Love plots for the two std diff dataframes side by side\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig.suptitle('Figure 2: Love Plots')\n",
    "# covariates = ['age', 'educ', 'black', 'hisp', 'marr', 'nodegree', 're74', 're75', 'u74', 'u75']\n",
    "\n",
    "# TODO for both plots, set the x-axis limits to be the same\n",
    "# axs[0].set_title(TODO)\n",
    "# axs[0].set_xlim(-2.5, 2.5)\n",
    "\n",
    "# axs[1].set_title(TODO)\n",
    "# axs[1].set_xlim(-2.5, 2.5)\n",
    "\n",
    "# save the figure for viewing later\n",
    "fig.savefig('fig2_love_plots.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of reporting a table of estimates and confidence intervals, for this project we will generate two figures for illustrating the estimates and confidence intervals for the observational and trimmed datasets. We provide a `build_estimator_error_bars` function that helps generate the error bar plots for the various estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def build_estimator_error_bars(estimator_dict, ax):\n",
    "    \"\"\"\n",
    "    Given a dictionary of estimator results and an axis, generates the error bar plots for the estimators, \n",
    "    where the x-axis is the estimator name, the y-axis is the point estimate, and the error bars are the 95% confidence interval.\n",
    "\n",
    "    Args:\n",
    "        estimator_dict (dict): A dictionary of estimator results\n",
    "        ax (plt.Axes): The axis to plot the error bars on\n",
    "\n",
    "    Returns:\n",
    "        ax (plt.Axes): The axis with the error bars plotted\n",
    "    \"\"\"\n",
    "    \n",
    "    est_df = pd.DataFrame(columns=['estimator', 'point_estimate', 'lower_ci', 'upper_ci'])\n",
    "    for estimator, results in estimator_dict.items():\n",
    "        est_df = pd.concat([est_df if not est_df.empty else None,\n",
    "        pd.DataFrame({\n",
    "            'estimator': [estimator],\n",
    "            'point_estimate': [results['point_estimate']],\n",
    "            'lower_ci': [results['ci'][0]],\n",
    "            'upper_ci': [results['ci'][1]]\n",
    "        })], ignore_index=True)\n",
    "\n",
    "    est_df['yerr_lower'] = est_df['point_estimate'] - est_df['lower_ci']\n",
    "    est_df['yerr_upper'] = est_df['upper_ci'] - est_df['point_estimate']\n",
    "    \n",
    "    ax.errorbar(\n",
    "        x=range(len(est_df)),\n",
    "        y=est_df['point_estimate'],\n",
    "        yerr=[est_df['yerr_lower'], est_df['yerr_upper']],\n",
    "        fmt='o', # draw a circle at each point\n",
    "        capsize=5, # draw a line at the end of the error bar\n",
    "        color=sns.color_palette()[0], # use the first color in the seaborncolor palette\n",
    "        \n",
    "    )\n",
    "    ax.set_xticks(range(len(est_df)))\n",
    "    ax.set_xticklabels(est_df['estimator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we had the following dictionary of estimators:\n",
    "\n",
    "```python\n",
    "estimator_dict = {\n",
    "    'estimator1': {\n",
    "        'point_estimate': 1.0,\n",
    "        'ci': [0.9, 1.1]\n",
    "    },\n",
    "    'estimator2': {\n",
    "        'point_estimate': 0.5,\n",
    "        'ci': [0.4, 0.6]\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "The function call `build_estimator_error_bars(estimator_dict, ax)` would generate a plot that looks like this:\n",
    "\n",
    "<div style=\"max-width:500px; margin: auto;\"> \n",
    "\n",
    "![](../images/proj2_example_error_bars.png)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by generating the results for each estimator using the `generate_estimates` helper function provided earlier in the notebook according to the table below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Results Name | estimator_func | data |\n",
    "|------------|-----------|---------|\n",
    "| `naive` | `reg_diff_in_means` | `observational_df` |\n",
    "| `matching` | `reg_diff_in_means` | `matched_df` |\n",
    "| `ipw` | `ipw_att` | `observational_df` |\n",
    "| `naive_trimmed` | `reg_diff_in_means` | `trimmed_df` |\n",
    "| `matching_trimmed` | `reg_diff_in_means` | `matched_trimmed_df` |\n",
    "| `ipw_trimmed` | `ipw_att` | `trimmed_df` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO call generate_estimates for each estimator, this cell may take ~20-30 seconds to run\n",
    "naive = None #generate_estimates(data=observational_df, estimator_func=reg_diff_in_means, treat_col='treat', outcome_col='re78')\n",
    "matching = None\n",
    "ipw = None\n",
    "naive_trimmed = None\n",
    "matching_trimmed = None\n",
    "ipw_trimmed = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Figure 3**: Build a side by side plot of the estimators for the observational and trimmed datasets. The goal is to produce a plot similar to figure 3 in [Imbens and Xu 2024](https://arxiv.org/abs/2406.00827), except that we will put our two plot panels side by side instead of on top of each other.\n",
    "\n",
    "<div style=\"max-width:800px; margin: auto;\"> \n",
    "\n",
    "![](../images/proj2_imbens_xu_fig3.png)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the experimental results as reference lines for the true ATT effect (the red lines and regions in Imbens and Xu 2024 above). We'll plot our three estimators (naive, matching, IPW) for the full observational dataset in the left panel, and our three estimators for the trimmed dataset in the right panel. As always, be sure to label the axes and add titles as appropriate. The units of the y-axis are in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# load in the experimental dataset for a reference line\n",
    "experimental_df = pd.read_csv('~/COMSC-341CD/data/nsw_experimental.csv')\n",
    "\n",
    "# TODO call generate_estimates for the experimental dataset using the reg_diff_in_means estimator\n",
    "experiment_results = None\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Figure 3: Estimator Comparison')\n",
    "\n",
    "#### axs[0] ####\n",
    "# axs[0].set_title(TODO)\n",
    "\n",
    "# TODO plot the experimental point estimate as a horizontal red solid line and the 95% confidence intervals as dotted red lines\n",
    "# Optionally, you can use ax.fill_between() to shade the 95% confidence interval region\n",
    "#ax.hline(TODO)\n",
    "\n",
    "observational_estimators = {\n",
    "    'naive difference-in-means': naive,\n",
    "    'matched difference-in-means': matching,\n",
    "    'IPW': ipw\n",
    "}\n",
    "\n",
    "# TODO call the build_estimator_error_bars function for the observational_estimators dictionary\n",
    "# build_estimator_error_bars(estimator_dict=TODO, ax=TODO)\n",
    "\n",
    "# fix the y-axis limits to be the same for both plots\n",
    "# axs[0].set_ylim(-10000, 4000)\n",
    "\n",
    "\n",
    "#### axs[1] ####\n",
    "# TODO repeat the same plot as axs[1] for the trimmed estimators, including the experimental reference line and confidence intervals\n",
    "# axs[1].set_title(TODO)\n",
    "\n",
    "trimmed_estimators = {\n",
    "    'naive difference-in-means': naive_trimmed,\n",
    "    'matched difference-in-means': matching_trimmed,\n",
    "    'IPW': ipw_trimmed\n",
    "}\n",
    "# TODO call the build_estimator_error_bars function for the trimmed_estimators dictionary\n",
    "# build_estimator_error_bars(estimator_dict=TODO, ax=TODO)\n",
    "\n",
    "# fix the y-axis limits to be the same for both plots\n",
    "# axs[0].set_ylim(-10000, 4000)\n",
    "\n",
    "# save the figure for viewing later\n",
    "fig.savefig('fig3_estimator_comparison.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    ":::{tip}\n",
    "\n",
    "If it is more convenient for you to view your notebook in one window and answer questions in another, you can copy the questions below into a separate document and answer them there. Then, you can copy your responses back into the notebook for submission.\n",
    "\n",
    "The figures you generated above are also saved and embedded inline below to make it easier to answer the questions. You may need to \"refresh\" the cell by double-clicking on them and then executing the cell again to view them.\n",
    "\n",
    ":::\n",
    "\n",
    "## 2. Prior Knowledge and Causal Question\n",
    "\n",
    "Given the description of the NSW program above, answer the following questions:\n",
    "\n",
    "2.1. Briefly discuss why the ATT may be a more appropriate causal quantity to focus on when evaluating the NSW program's effectiveness as opposed to the ATE or ATU.\n",
    "\n",
    "2.2. Suppose that the observational dataset was collected in a way such that participants self-selected into the program -- in other words, individuals voluntarily chose whether to participate in the program. The study designers then collected the list of covariates above as confounders to satisfy the conditional exchangeability assumption. Given the description of the NSW program, briefly discuss one potential confounder that might be missing from the covariate list. In your discussion, be sure to include why you believe that confounder could affect both an individual's participation in the NSW job training program and their subsequent earnings.\n",
    "\n",
    ":::{admonition} Note\n",
    "\n",
    "The reason why the LaLonde and other researchers treat conditional exchangeability as plausible in the real data is because their \"observational\" dataset is partially constructed from the experimental dataset. Question 2.2 is operating under the assumption that the observational dataset is fully constructed from the self-selected participants, in which case conditional exchangeability would have been much more difficult to justify.\n",
    "\n",
    ":::\n",
    "\n",
    "**TODO your responses**:\n",
    "\n",
    "2.1:\n",
    "\n",
    "2.2:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Design\n",
    "\n",
    "![](fig1_propensity_score_distribution.png)\n",
    "\n",
    "![](fig2_love_plots.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3.1. Examining your propensity score distributions in Figure 1, does there appear to be any evidence of positivity violations? Are there any regions where the propensity score distribution may be problematic in terms of severe imbalance between the number of treated and control units?\n",
    "\n",
    "3.2. Looking at the left panel Love plot for the full observational dataset in Figure 2, which covariate was the most unbalanced in the unmatched dataset, and which covariate was most balanced in the unmatched dataset? Does the matching process appear to have been effective at balancing the covariates?\n",
    "\n",
    "3.3. Comment on what you observe in your right panel Love plot for the trimmed dataset in Figure 2. Does matching seem to be more beneficial for trimmed or untrimmed data?\n",
    "\n",
    "**TODO your responses**:\n",
    "\n",
    "3.1:\n",
    "\n",
    "3.2:\n",
    "\n",
    "3.3:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 4. Estimation and Interpretation\n",
    "\n",
    "![](fig3_estimator_comparison.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "4.1. Looking at your left panel of estimator results in Figure 3 for the full observational dataset, which estimator appears to be most biased compared to the experimental ATT estimate? Briefly discuss why you think this estimator is biased. Some things to potentially consider are what causal assumptions are being made/violated, or whether covariates are being controlled for.\n",
    "\n",
    "4.2. Which estimator appears to best match the experimental ATT estimates with the full observational dataset in your left panel of Figure 3? \n",
    "\n",
    "4.3. Comment on any changes you observe for all three estimators in the right panel of Figure 3 with the trimmed dataset. Which estimator(s) appear to benefit from trimming the propensity score?\n",
    "\n",
    "4.4. Given that the causal quantity we have been estimating is the ATT and the experimental point estimate is $1,794, state an interpretation of this result in the context of the treatment and outcome of the study. \n",
    "\n",
    "**TODO your responses**:\n",
    "\n",
    "4.1:\n",
    "\n",
    "4.2:\n",
    "\n",
    "4.3:\n",
    "\n",
    "4.4:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Reflection\n",
    "\n",
    "5.1. How much time did you spend on this assignment?\n",
    "\n",
    "5.2. Were there any parts of the assignment that you found particularly challenging?\n",
    "\n",
    "5.3. What is one thing you have a better understanding of after completing this assignment and going through the class content?\n",
    "\n",
    "5.4. Do you have any follow-up questions about concepts that you'd like to explore further?\n",
    "\n",
    "**TODO your responses**:\n",
    "\n",
    "5.1:\n",
    "\n",
    "5.2:\n",
    "\n",
    "5.3:\n",
    "\n",
    "5.4:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional Extensions\n",
    "\n",
    "- We have implemented the most fundamental matching and IPW estimators in this project. There has been extensive work on variations of these estimators, including:\n",
    "    - K:1 matching, where multiple controls are matched to each treated unit\n",
    "    - augmented IPW, where the propensity score is augmented with a flexible model\n",
    "- There have also been explorations of using machine learning methods to estimate the propensity score, and whether these provide better balance and/or more efficient estimators.\n",
    "- To learn more about how these variations can be implemented, see the latter sections of [Austin 2011](https://pmc.ncbi.nlm.nih.gov/articles/PMC3144483/pdf/hmbr46-399.pdf) and [Imbens and Xu 2024](https://arxiv.org/abs/2406.00827)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "This assignment uses data from Nick Huntington-Klein's `causaldata` package, which provides convenient access to the Lalonde dataset. This project is based on Chapter 5 of Scott Cunningham's [Causal Inference: The Mixtape](https://mixtape.scunning.com/) as well as [Imbens and Xu 2024: Lalonde (1986) after Nearly Four Decades: Lessons Learned](https://arxiv.org/abs/2406.00827)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
