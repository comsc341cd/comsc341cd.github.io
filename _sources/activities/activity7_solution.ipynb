{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(activity7_solution)=\n",
    "# Activity 7 Solution: Positivity and regression in Yeager et al. 2019\n",
    "\n",
    "**2025-03-04**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schoolid</th>\n",
       "      <th>intervention</th>\n",
       "      <th>achievement_score</th>\n",
       "      <th>success_expect</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>frst_in_family</th>\n",
       "      <th>school_urbanicity</th>\n",
       "      <th>school_mindset</th>\n",
       "      <th>school_achievement</th>\n",
       "      <th>school_ethnic_minority</th>\n",
       "      <th>school_poverty</th>\n",
       "      <th>school_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277359</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.449646</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>0.769703</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.121763</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1.526147</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.334544</td>\n",
       "      <td>0.648586</td>\n",
       "      <td>-1.310927</td>\n",
       "      <td>0.224077</td>\n",
       "      <td>-0.426757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   schoolid  intervention  achievement_score  success_expect  ethnicity  \\\n",
       "0        76             1           0.277359               6          4   \n",
       "1        76             1          -0.449646               4         12   \n",
       "2        76             1           0.769703               6          4   \n",
       "3        76             1          -0.121763               6          4   \n",
       "4        76             1           1.526147               6          4   \n",
       "\n",
       "   gender  frst_in_family  school_urbanicity  school_mindset  \\\n",
       "0       2               1                  4        0.334544   \n",
       "1       2               1                  4        0.334544   \n",
       "2       2               0                  4        0.334544   \n",
       "3       2               0                  4        0.334544   \n",
       "4       1               0                  4        0.334544   \n",
       "\n",
       "   school_achievement  school_ethnic_minority  school_poverty  school_size  \n",
       "0            0.648586               -1.310927        0.224077    -0.426757  \n",
       "1            0.648586               -1.310927        0.224077    -0.426757  \n",
       "2            0.648586               -1.310927        0.224077    -0.426757  \n",
       "3            0.648586               -1.310927        0.224077    -0.426757  \n",
       "4            0.648586               -1.310927        0.224077    -0.426757  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and examine the data\n",
    "learning_df = pd.read_csv(\"~/COMSC-341CD/data/learning_mindset.csv\")\n",
    "learning_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_df['achievement_score'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This selected portion of the National Study of Learning Mindsets dataset is not truly randomized, so we'll need to adjust for confounding.\n",
    "\n",
    "The columns we will look at are:\n",
    "\n",
    "- `intervention`: $T$ whether the student received the intervention (1) or not (0)\n",
    "- `success_expect`: student prior mindset about their ability to succeed in school (higher values indicate a stronger belief in their ability to succeed)\n",
    "- `frst_in_family`: whether the student would be the first in their family to attend college (1) or not (0)\n",
    "- `gender`: student's self-reported gender\n",
    "- `school_urbanicity`: categorical variable corresponding to the urbanicity of the school the student attends, e.g. urban, suburban, rural\n",
    "- `achievement_score`: $Y$ the student's future grade achievement, standardized such that 0 is the mean and it has a standard deviation of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Imbalance in covariates\n",
    "\n",
    "In this vesrion of the dataset we are anlayzing, there appear to be some differences in the distribution of covariates between the treatment and control groups where participants have different probabilities of receiving the intervention.\n",
    "\n",
    "## 1.1\n",
    "\n",
    "Perform two separate `groupby` operations to compute the mean of `intervention`, grouping by: \n",
    "\n",
    "- `success_expect`\n",
    "- `frst_in_family`\n",
    "\n",
    "What do you observe? Are certain groups of students more or less likely to receive the growth mindset video? Keep in mind that `intervention=1` corresponds to the growth mindset video intervention.\n",
    "\n",
    "**Your response**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_expect\n",
      "1    0.271739\n",
      "2    0.265957\n",
      "3    0.294118\n",
      "4    0.271617\n",
      "5    0.311070\n",
      "6    0.354287\n",
      "7    0.362319\n",
      "Name: intervention, dtype: float64\n",
      "frst_in_family\n",
      "0    0.353325\n",
      "1    0.309487\n",
      "Name: intervention, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# TODO perform two separate groupby operations\n",
    "print(learning_df.groupby(['success_expect'])['intervention'].mean())\n",
    "print(learning_df.groupby(['frst_in_family'])['intervention'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Examining positivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = ['success_expect', 'frst_in_family']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seeen some potential confounding in `success_expect` and `frst_in_family`, let's try to control for them. If we take the same strategy as we have done before with stratification, we'll need to bin on the confounders and compute treatment effects for each bin.\n",
    "\n",
    "However, we also need to be careful about positivity violations. First, let's compute the total number of bins we need to create if we want to control for these two covariates.\n",
    "\n",
    "We can do this by using [pd.Series.nunique](https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html) to get the number of unique values for each covariate and then multiplying them together. This is like taking a cross product over the all possible values of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_df['frst_in_family'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bins: 14\n"
     ]
    }
   ],
   "source": [
    "# TODO calculate the total number of bins \n",
    "total_bins = learning_df['frst_in_family'].nunique() * learning_df['success_expect'].nunique()\n",
    "\n",
    "print(f\"Total number of bins: {total_bins}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's check if positivity holds. We can do this by grouping over the covariiats plus the intervention, and then counting the number of unique groups are actually present in the data.\n",
    "\n",
    "To generate the per-bin counts, we perform a `groupby(all_cols, as_index=False)` over the intervention and all combinations of the other columns, and the check the `ngroups` attribute of the resulting groupby object. How many groups are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number actual groups among the bins for ['intervention', 'success_expect', 'frst_in_family']: 28\n"
     ]
    }
   ],
   "source": [
    "# Group by the intervention column and the two covariates\n",
    "all_cols = ['intervention', 'success_expect', 'frst_in_family']\n",
    "group_count = learning_df.groupby(all_cols, as_index=False).ngroups\n",
    "\n",
    "\n",
    "print(f\"Number actual groups among the bins for {all_cols}: {group_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need each bin to have both control and treatment units in order to have a valid comparison, the total number of groups should be equal to **2 times the total number of bins possible** for there to be no positivity violations.\n",
    "\n",
    "Does the number of groups you found in 2.1 match this?\n",
    "\n",
    "**Your response**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally we'd like to control for as many confounders as possible to make conditional exchangeability more plausible. Let's now add `gender` and `school_urbanicity` to our list of covariates, making a total of 4 confounders.\n",
    "\n",
    "Repeat the analysis above with the new set of covariates. Do we see positivity violations with the new set of covariates?\n",
    "\n",
    "**Your response**: TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number actual groups among the bins for ['intervention', 'success_expect', 'gender', 'frst_in_family', 'school_urbanicity']: 264\n",
      "Expected number of groups for positivity to hold: 280\n"
     ]
    }
   ],
   "source": [
    "# TODO your code here \n",
    "all_cols = ['intervention', 'success_expect', 'gender', 'frst_in_family', 'school_urbanicity',]\n",
    "group_count = learning_df.groupby(all_cols, as_index=False).ngroups\n",
    "\n",
    "\n",
    "print(f\"Number actual groups among the bins for {all_cols}: {group_count}\")\n",
    "\n",
    "expected_count = np.prod([learning_df[col].nunique() for col in all_cols[1:]]) * 2\n",
    "\n",
    "print(f\"Expected number of groups for positivity to hold: {expected_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Regression for adjustment estimation\n",
    "\n",
    "In Parts 1 and 2, we observed covariate imbalances and potential positivity violations when trying to use stratification for adjustment. Let's now use regression as an alternative approach for estimating the causal effect while controlling for confounders.\n",
    "\n",
    "## 3.1\n",
    "\n",
    "Regression can be used to estimate causal effects when we have conditional exchangeability. If we assume that we have measured all confounders and included them in our regression model, then the coefficient on the treatment variable can be interpreted as the average treatment effect (ATE).\n",
    "\n",
    "\n",
    "Let's first import the [statsmodels formula API](https://www.statsmodels.org/stable/api.html#formulas):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# canonical import for the formula API\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's fit a naive regression model that doesn't adjust for any confounders. We'll use the following formula:\n",
    "\n",
    "```python\n",
    "formula = 'outcome ~ 1 + treatment' # equivalent to outcome = beta_0 + beta_1 treatment\n",
    "```\n",
    "\n",
    "This formula tells statsmodels to fit a model where the outcome is regressed on the treatment variable and the intercept (1). We then pass that string to the `smf.ols` function, along with the data and the model formula:\n",
    "\n",
    "```python\n",
    "model = smf.ols(formula, data=data).fit()\n",
    "```\n",
    "\n",
    "The parameter estimates are stored in the `params` attribute of the model object:\n",
    "\n",
    "```python\n",
    "model.params\n",
    "```\n",
    "\n",
    "Fit a naive regression model on the `intervention` and `achievement_score` variables. What is the fitted coefficient for `intervention`? \n",
    "\n",
    "**Your response**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['schoolid', 'intervention', 'achievement_score', 'success_expect',\n",
       "       'ethnicity', 'gender', 'frst_in_family', 'school_urbanicity',\n",
       "       'school_mindset', 'school_achievement', 'school_ethnic_minority',\n",
       "       'school_poverty', 'school_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept      -0.153803\n",
       "intervention    0.472272\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO fit a naive rgression model and check the params attribute\n",
    "formula = 'achievement_score ~ 1 + intervention'\n",
    "model = smf.ols(formula, data=learning_df).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2\n",
    "\n",
    "Next, let's fit a model that adjusts for the confounders we identified in Part 1.\n",
    "\n",
    "We can do this by adding the confounders to the formula:\n",
    "\n",
    "```python\n",
    "formula = 'outcome ~ 1 + treatment + confounder1 + confounder2'\n",
    "```\n",
    "\n",
    "How does the coefficient on `intervention` change when we adjust for the confounders?\n",
    "\n",
    "**Your response**: TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept        -2.023493\n",
       "intervention      0.414097\n",
       "success_expect    0.373244\n",
       "frst_in_family   -0.123081\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO fit a model that adjusts for the confounders and check the params attribute\n",
    "formula = 'achievement_score ~ 1 + intervention + success_expect + frst_in_family'\n",
    "model = smf.ols(formula, data=learning_df).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "We'll have more opportunities to practice with statsmodels and linear regression in Worksheet 4!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Optional extra\n",
    "\n",
    "\n",
    "if we actually want to see the bins that are missing, we can generate a [pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) of the counts, and then identify the bins that are missing in either the control or treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins with no control units:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>intervention</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>success_expect</th>\n",
       "      <th>gender</th>\n",
       "      <th>frst_in_family</th>\n",
       "      <th>school_urbanicity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "intervention                                              0    1\n",
       "success_expect gender frst_in_family school_urbanicity          \n",
       "1              1      0              1                  0.0  2.0\n",
       "2              1      0              1                  0.0  2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bins with no treatment units:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>intervention</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>success_expect</th>\n",
       "      <th>gender</th>\n",
       "      <th>frst_in_family</th>\n",
       "      <th>school_urbanicity</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "intervention                                               0    1\n",
       "success_expect gender frst_in_family school_urbanicity           \n",
       "1              1      0              0                   1.0  0.0\n",
       "                                     2                   2.0  0.0\n",
       "                      1              0                   3.0  0.0\n",
       "               2      0              0                   2.0  0.0\n",
       "                                     1                   1.0  0.0\n",
       "                                     2                   1.0  0.0\n",
       "2              1      0              0                   2.0  0.0\n",
       "                                     3                   2.0  0.0\n",
       "                      1              1                  10.0  0.0\n",
       "               2      0              3                   4.0  0.0\n",
       "3              1      0              0                   5.0  0.0\n",
       "                                     2                  11.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_cols = ['success_expect', 'gender', 'frst_in_family', 'school_urbanicity', 'intervention']\n",
    "count_df = learning_df.groupby(all_cols, as_index=False).size()\n",
    "\n",
    "# Create a pivot table to show counts by intervention and bins\n",
    "bin_pivot = pd.pivot_table(\n",
    "    count_df, \n",
    "    index=['success_expect', 'gender', 'frst_in_family', 'school_urbanicity'],\n",
    "    columns=['intervention'],\n",
    "    values='intervention',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Display information about the pivot table\n",
    "print(\"Bins with no control units:\")\n",
    "display(bin_pivot[bin_pivot[0] == 0])\n",
    "\n",
    "print(\"Bins with no treatment units:\")\n",
    "display(bin_pivot[bin_pivot[1] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# References\n",
    "\n",
    "- Yeager, D. S. et al. (2019). A national experiment reveals where a growth mindset improves achievement. Nature.\n",
    "- Athey, S., & Wager, S. (2019). Estimating treatment effects with causal forests: An application. Observational studies.\n",
    "- Facure, M. (2023). Causal Inference for the Brave and the True."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
