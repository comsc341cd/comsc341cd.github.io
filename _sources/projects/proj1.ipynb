{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08a8b91-ca55-4170-9688-da07283e7000",
   "metadata": {},
   "source": [
    "(proj1)=\n",
    "# Project 1 ðŸ‘¶\n",
    "\n",
    ":::{epigraph}\n",
    "Randomized Experiments\n",
    "\n",
    "-- TODO your name here\n",
    ":::\n",
    "\n",
    ":::{admonition} Collaboration Statement\n",
    "- TODO brief statement on the nature of your collaboration.\n",
    "- TODO your collaborator's names here.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9ff5c-faf3-472c-a92a-629dd6e12023",
   "metadata": {},
   "source": [
    "In this project, we will conduct our first causal study start to finish by examining the Infant Health and Development Program (IHDP) dataset, which is a classic dataset in the causal inference literature.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "- Practice following the causal roadmap with a real-world dataset.\n",
    "- Explore the benefits of stratification in a randomized experiment.\n",
    "- Translate mathematical quantities into code by implementing two difference-in-means estimators.\n",
    "- Exercise your data manipulation and visualization skills with real and simulated data.\n",
    "\n",
    ":::{note}\n",
    "This project is due **Monday 3/3 at 11:55pm.**\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798f667a-062f-4ba6-a3f6-d9e2b73f6c39",
   "metadata": {},
   "source": [
    "## Table of Contents and Rubric\n",
    "\n",
    "| Section | Points |\n",
    "|------------------------------------|-------|\n",
    "| [Math to code: difference-in-means implementation](difference-in-means) | 2 |\n",
    "| [Interactivity: stratified vs unstratified estimators](exploring-the-efficiency-of-difference-in-means-estimators) | 2 |\n",
    "| [Causal question and study design: IHDP](causal-study-design-ihdp) | 2.5 |\n",
    "|  [Bootstrap utilities](bootstrap-utility-functions) | 0.5 |\n",
    "| [Estimation and interpretation: IHDP analysis](causal-estimation-and-interpretation-ihdp-analysis) | 2.5 |\n",
    "| [Reflection](reflection) | 0.5 |\n",
    "| Total |10 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3378986d",
   "metadata": {},
   "source": [
    ":::{admonition} Grading guidelines\n",
    "\n",
    "The course projects offer an opportunity to practice the full causal inference workflow, from building estimators and formulating questions to conducting analyses and communicating your findings effectively. Here are some guidelines on how to approach the project:\n",
    "\n",
    "- Like the worksheets, a portion of points will be autograded -- feel free to submit as many times as you want to check your code's correctness!\n",
    "\n",
    "- For visualizations:\n",
    "    - Help your reader understand your findings through visually clear figures\n",
    "    - Label your axes, provide legends when appropriate, and add figure titles to provide context\n",
    "\n",
    "- For written responses:\n",
    "    - Support your ideas with specific evidence from your analysis or prior knowledge\n",
    "    - Write concisely but clearly -- one-word/one-phrase answers usually don't give enough space to show what you've learned\n",
    "\n",
    "If you're uncertain about any portion of the project, please do come to office hours, TA hours, or reach out on Ed! \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eab687-cb6c-45f4-b163-a02b2c1fcf5d",
   "metadata": {},
   "source": [
    "## How to submit\n",
    "\n",
    "Like our worksheets, follow the instructions on the course website to submit your completed `proj1.ipynb` and `proj1.py` files, along with your causal graph image for the Infant Health and Development Program analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581dc269-fca1-47f2-aee4-4217ac164371",
   "metadata": {},
   "source": [
    "## Notebook imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb30567-2d75-49ed-bb55-26f4f4619dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interact_manual, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31c67f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c705990c-5703-4289-a847-f021993325fe",
   "metadata": {},
   "source": [
    "## 1. Difference-in-means\n",
    "\n",
    "We begin by simulating a randomized experiment, where there are the following variables:\n",
    "\n",
    "- $T$: the binary intervention of interest\n",
    "- $Y$: the outcome of interest\n",
    "- $X$: a binary variable that affects the outcome of interest, which we will refer to as a **covariate**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f0b83e-5371-40ba-954d-af7447ecb4b1",
   "metadata": {},
   "source": [
    "We provide the following code for simulating a random experiment with a binary treatment $T$ and binary covariate $X$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a836806-964b-409a-8ad7-7879bf2bd3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "def sim_random_exp(n_samples=1000, treatment_effect=1.0, covariate_effect=3.0):\n",
    "    \"\"\"\n",
    "    Simulate a random experiment with a binary treatment and covariate.\n",
    "\n",
    "    Args:\n",
    "        n_samples (int): the number of samples to simulate\n",
    "        treatment_effect (float): the magnitude of the effect of the treatment on the outcome\n",
    "        covariate_effect (float): the magnitude of the effect of the covariate on the outcome\n",
    "\n",
    "    Returns:\n",
    "        Y (np.ndarray): the observed outcome\n",
    "        T (np.ndarray): the binary  treatment assignment\n",
    "        X (np.ndarray): the binary covariate\n",
    "    \"\"\"\n",
    "    # Generate potential outcomes\n",
    "    Y0 = rng.normal(size=n_samples)\n",
    "    Y1 = Y0 + treatment_effect\n",
    "\n",
    "    # Randomly assign treatment\n",
    "    T = rng.choice([0, 1], size=n_samples, )\n",
    "\n",
    "    # Create a binary covariate that affects the outcome\n",
    "    X = rng.choice([0, 1], size=n_samples)\n",
    "\n",
    "    # Generate the observed outcome\n",
    "    Y = np.where(T == 1, Y1, Y0) + covariate_effect*X\n",
    "\n",
    "    return Y, T, X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30926e2",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "The parameter `covariate_effect` is the magnitude of the effect of the covariate on the outcome  -- the larger the value, the stronger the effect of the covariate on the outcome.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30cb43-40ba-4052-a5c2-b438dd67bfd0",
   "metadata": {},
   "source": [
    "Under a randomized experiment study design, we are able to **identify** the average treatment effect ($ATE$):\n",
    "\n",
    "$$\n",
    "ATE = E[Y(1) - Y(0)] \\; \\xrightarrow[]{\\text{Identification}} \\; E[Y | T = 1] - E[Y | T = 0]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732668b0",
   "metadata": {},
   "source": [
    "We can then **estimate** the causal effect by taking the difference in means between the treated and control groups, which is known as the **difference-in-means** estimator:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[Y | T=1] - E[Y | T=0] \\; \\xrightarrow[]{\\text{Estimation}} \\; &\\hat{E}[Y | T=1] - \\hat{E}[Y | T=0] \\\\\n",
    "= &\\frac{1}{n_1} \\sum_{i=1}^{n} \\mathbb{I}(T_i = 1) Y_i - \\frac{1}{n_0} \\sum_{i=1}^{n} \\mathbb{I}(T_i = 0) Y_i\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "where $n_1$ is the number of samples in the treatment group, and $n_0$ is the number of samples in the control group. That is: \n",
    "\n",
    "$$\n",
    "n_0 = \\sum_{i=1}^{n} \\mathbb{I}(T_i = 0)\\\\\n",
    "n_1 = \\sum_{i=1}^{n} \\mathbb{I}(T_i = 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6260ca16",
   "metadata": {},
   "source": [
    "### 1.1. Implement `diff_in_means`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dcb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_in_means(Y, T):\n",
    "    \"\"\"\n",
    "    Computes the difference in means between the treatment and control groups.\n",
    "\n",
    "    Args:\n",
    "        Y (np.ndarray or pd.Series): the observed outcome\n",
    "        T (np.ndarray or pd.Series): the binary treatment assignment\n",
    "\n",
    "    Returns:\n",
    "        float: the difference in means estimate\n",
    "    \"\"\"\n",
    "    assert Y.shape == T.shape, \"Y and T must have the same shape\"\n",
    "    \n",
    "    # TODO your code here\n",
    "    return 0\n",
    "\n",
    "test_Y = np.array([2, 1, 2, 1])\n",
    "test_T = np.array([1, 0, 1, 0])\n",
    "\n",
    "assert np.isclose(diff_in_means(test_Y, test_T), 1)\n",
    "# Feel free to add more tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa76329c",
   "metadata": {},
   "source": [
    "### 1.2. Implement `stratified_diff_in_means`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0c2e1",
   "metadata": {},
   "source": [
    "We saw in class that if we want to include a covariate in our analysis, we can analogously compute the difference in means between the treated and control groups, but now conditioning on the covariate. \n",
    "\n",
    "We implement this here as a **stratified difference-in-means** estimator, which we call $\\widehat{ATE}_\\text{stratified}$:\n",
    "\n",
    "$$\n",
    "\\widehat{ATE}_\\text{stratified} = \\sum^K_{k=1} \\frac{n_k}{n} \\widehat{ATE}_k\n",
    "$$\n",
    "\n",
    "where $K$ are the total number of strata, $n_k$ is the number of samples in stratum $k$, and $\\widehat{ATE}_k$ is the difference-in-means estimator for stratum $k$. This is saying that we're computing the difference in means for each stratum, and then taking a weighted average of the stratum-level estimates, where the weights are the proportion of samples in each stratum. $\\widehat{ATE}_k$ is defined as:\n",
    "\n",
    "$$\n",
    "\\widehat{ATE}_k = \\frac{1}{n_{k1}} \\sum_{i=1}^{n} \\mathbb{I}(X_i = k \\text{ and } T_i = 1) Y_i - \\frac{1}{n_{k0}} \\sum_{i=1}^{n} \\mathbb{I}(X_i = k \\text{ and } T_i = 0) Y_i\n",
    "$$\n",
    "\n",
    "where $n_{k1}$ is the number of samples in the treatment group for stratum $k$, and $n_{k0}$ is the number of samples in the control group for stratum $k$. That is:\n",
    "\n",
    "\n",
    "$$\n",
    "n_{k1} = \\sum_{i=1}^{n} \\mathbb{I}(X_i = k \\text{ and } T_i = 1)\\\\\n",
    "n_{k0} = \\sum_{i=1}^{n} \\mathbb{I}(X_i = k \\text{ and } T_i = 0)\n",
    "$$\n",
    "\n",
    "We'll be implementing this estimator for the case when $X$ is binary so there are only two strata, $k \\in \\{0, 1\\}$.\n",
    "\n",
    ":::{tip} Hint\n",
    "\n",
    "While these equations may look a bit complicated, notice that each individual summation term in $\\widehat{ATE}_k$ is just a mean of the outcome for a given subset of the data. In particular, in our case where $X$ is binary:\n",
    "\n",
    "- $\\frac{1}{n_{11}} \\sum_{i=1}^{n} \\mathbb{I}(X_i = 1 \\text{ and } T_i = 1) Y_i$ is the mean of the outcome when $X=1$ and $T=1$\n",
    "- $\\frac{1}{n_{10}} \\sum_{i=1}^{n} \\mathbb{I}(X_i = 1 \\text{ and } T_i = 0) Y_i$ is the mean of the outcome when $X=1$ and $T=0$\n",
    "- and analogously for $X=0$\n",
    "\n",
    "You can then use numpy's boolean indexing to compute the means for each stratum.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0081e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_in_means_stratified(Y, T, X):\n",
    "    \"\"\"\n",
    "    Compute the difference in means stratified by binary covariate X.\n",
    "\n",
    "    NOTE: stratified difference in means may be undefined if strata are empty.\n",
    "\n",
    "    Args:\n",
    "        Y (np.ndarray or pd.Series): the observed outcome\n",
    "        T (np.ndarray or pd.Series): the binary treatment assignment\n",
    "        X (np.ndarray or pd.Series): the binary covariate\n",
    "\n",
    "    Returns:\n",
    "        float: the difference in means estimate\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO your code here\n",
    "    return 0\n",
    "\n",
    "test_Y = np.array([2, 1, 2, 1])\n",
    "test_T = np.array([1, 0, 1, 0])\n",
    "test_X = np.array([1, 1, 0, 0])\n",
    "\n",
    "assert np.isclose(diff_in_means_stratified(test_Y, test_T, test_X), 1)\n",
    "# Feel free to add more tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81abc889",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21b0b54",
   "metadata": {},
   "source": [
    "## 2. Exploring the efficiency of difference-in-means estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c3a3f1",
   "metadata": {},
   "source": [
    "### 2.1 Interactive widget\n",
    "\n",
    "Next, complete the `gen_experiment_results` function to simulate `n_experiments` random experiments and compute the difference-in-means and stratified difference-in-means estimates.\n",
    "\n",
    ":::{tip}\n",
    "The function declaration below uses the `**kwargs` syntax to pass additional keyword arguments to the `sim_random_exp` function. This is a useful way to write functions that are flexible and can take in different sets of arguments. For more information on the `**kwargs` syntax, see this [tutorial](https://realpython.com/python-kwargs-and-args/).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c12239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_experiment_results(n_experiments=10000, **kwargs):\n",
    "    \"\"\"\n",
    "    Simulates n_experiments random experiments and computes the difference-in-means\n",
    "    and stratified difference-in-means estimators.\n",
    "\n",
    "    Args:\n",
    "        n_experiments (int): the number of experiments to simulate\n",
    "        **kwargs: additional keyword arguments to pass directly `sim_random_exp`\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a dataframe with the results of the experiments in each row\n",
    "        \n",
    "        The dataframe should have two columns:\n",
    "        - diff_in_means: the difference in means estimator\n",
    "        - diff_in_means_stratified: the stratified difference in means estimator\n",
    "    \"\"\"\n",
    "    experiment_results = {\n",
    "        \"diff_in_means\": [],\n",
    "        \"diff_in_means_stratified\": []\n",
    "    }\n",
    "\n",
    "    for i in range(n_experiments):\n",
    "        # TODO pass **kwargs to sim_random_exp to return Y, T, X\n",
    "\n",
    "        # TODO populate the experiment_results dictionary\n",
    "\n",
    "    # Converts dictionary to dataframe with keys as column names\n",
    "    exp_df = pd.DataFrame(experiment_results)\n",
    "\n",
    "    return exp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230abedd",
   "metadata": {},
   "source": [
    "Using the `gen_experiment_results` function, create a manual interactive widget that plots the both the stratified and unstratified difference-in-means for a range of covariate effects. Specifically, you should:\n",
    "\n",
    "- Add a `interact_manual` decorator to the `plot_experiment_simulations` function\n",
    "- Create a slider for the $X$ variable effect that can take values between 0 and 6\n",
    "- Fix the number of experiments to 10000, see the [tutorial reference on ipywidgets](https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html#fixing-arguments-using-fixed) from Worksheet 3\n",
    "- Call the `gen_experiment_results` function with the given number of experiments and covariate effect\n",
    "- Plot a histogram of the difference-in-means, unstratified and stratified for a given covariate effect: this should be a **single plot with two histograms on top of each other**, which can be achieved using `sns.histplot`\n",
    "- Additionally, plot the true difference in means as a vertical line on the same figure, which can be achieved using `plt.axvline`. The default treatment effect is `1.0`\n",
    "\n",
    "\n",
    ":::{note}\n",
    "Remember to follow good figure design practices by adding a legend, title, and axis labels.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed5317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add interact_manual decorator\n",
    "def plot_experiment_simulations(num_experiments=10000, covariate_effect=3.0):\n",
    "    \"\"\"\n",
    "    Plots the both the stratified and unstratified difference-in-means \n",
    "\n",
    "    Args:\n",
    "        num_experiments (int): the number of experiments to simulate\n",
    "        covariate_effect (float): the covariate effect to use in the experiments\n",
    "\n",
    "    Returns:\n",
    "        None, but shows the plot\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4114aa34",
   "metadata": {},
   "source": [
    "### 2.2 Interpretation\n",
    "\n",
    "Recall our discussions of the **variance** of causal effect estimators:\n",
    "\n",
    "- **Variance**: how much do the estimates for a given experiment vary? We can visually inspect this by looking at how \"spread out\" the histogram is.\n",
    "\n",
    "In addition to variance, researchers may also be interested in the statistical bias of an estimator:\n",
    "\n",
    "- **Bias**: how far off is the mean estimate off from the true value? We can visually inspect this by looking at where the histogram is \"centered.\" If the histogram is centered around the true value, then the estimator is unbiased, and if the histogram is not centered around the true value, then the estimator is said to be biased.\n",
    "\n",
    "Play around with the widget you created above, testing out different covariate effect values.\n",
    "\n",
    "1. What do you observe about the bias of the unstratified and stratified estimators? Is either biased?\n",
    "\n",
    "2. What do you observe about the variance of the unstratified and stratified estimators? Researchers sometime call estimators with lower variance to be **more efficient**. Is there an estimator that appears to be more efficient?\n",
    "\n",
    "3. What happens to the relative variance of the two estimators when you set the covariate effect to 0, and why you think this occurs?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff451a",
   "metadata": {},
   "source": [
    "**TODO** your responses here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eaf205",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74a54ae",
   "metadata": {},
   "source": [
    "## 3. The Infant Health and Development Program\n",
    "\n",
    "Let's now dive into analyzing a real-world study: the Infant Health and Development Program (IHDP). The IHDP was a randomized experiment conducted in the 1980s to evaluate the effectiveness of an early intervention program for low-birthweight, prematurely born infants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a100434",
   "metadata": {},
   "source": [
    "### 3.1 Prior Knowledge and Causal Question\n",
    "\n",
    "Read the following resources on the IHDP study:\n",
    "\n",
    "- [IHDP policy memo](https://policyforchildren.org/wp-content/uploads/2013/08/IHDP-Final-5.11.10.pdf)\n",
    "- [Brooks-Gunn et al. 1991](https://www.jpeds.com/article/S0022-3476(05)80896-0/pdf), pages 350-352\n",
    "\n",
    "\n",
    ":::{admonition} Reading Notes\n",
    ":class: note\n",
    "\n",
    "- **Content warning**: the reading contains the term \"mental retardation,\" which was commonly used in medical and policy discussions at the time but is now outdated and harmful. Today, the term \"intellectual disability\" is preferred and is used medically and [federally](https://www.specialolympics.org/stories/news/rosas-law-signed-into-law-by-president-obama).\n",
    "\n",
    "- The Brooks-Gunn et al. 1991 paper contains minute details about the study recruitment and data collection process. Don't worry about understanding every aspect of the study, but try to get a sense of the overall experimental design and the baseline characteristics reported in Table 1.\n",
    "\n",
    "- The original methods mention stratification by both birthweight and clinical site in the study design. Because the probability of treatment is the same for all stratified groups, both the stratified difference-in-means and unstratified difference-in-means are valid estimators. For the purposes of this project, we will analyze the efficiency of estimators that **post-stratify** by other covariates.\n",
    ":::\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1. The outcome of interest we will be analyzing is the **Stanford-Binet Intelligence Scale score** (IQ) at an age of 36 months (3 years), and our causal quantity is the **average treatment effect (ATE)** on the child's IQ score. Describe what causal question we are trying to answer in this dataset in terms of the causal quantity we are trying to identify.\n",
    "\n",
    "2. State what $Y(1)$ and $Y(0)$ are in your own words given the treatment and outcome of the study.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a9d596",
   "metadata": {},
   "source": [
    "**TODO** your responses here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a37b137",
   "metadata": {},
   "source": [
    "### 3.2 Study Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e997c7",
   "metadata": {},
   "source": [
    "Next, let's load the IHDP dataset and look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef5cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ihdp_raw = pd.read_csv('~/COMSC341-CD/data/ihdp_real.csv')\n",
    "ihdp_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359d6bb",
   "metadata": {},
   "source": [
    "There are 50 total columns in the dataframe, but we will only use the following columns for the project:\n",
    "\n",
    "- `bw`: birth weight in grams\n",
    "- `momage`: mother's age in years\n",
    "- `nnhealth`: neonatal health index, higher scores indicate better health\n",
    "- `momwhite`: binary indicator for maternal ethnicity: 1 if white, 0 otherwise\n",
    "\n",
    "- `iqsb.36`: outcome: Stanford-Binet IQ score at 36 months\n",
    "- `treat`: binary treatment assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ccf95b",
   "metadata": {},
   "source": [
    "Our study design is a randomized experiment, and we will assume that all of the assumptions that are needed to identify the average treatment effect hold. Answer the following questions:\n",
    "\n",
    "1. Suppose that our data did not come from a randomized experiment, and families were able to choose whether or not to participate in the intervention. Select two of the four variables listed above that you think may confound the relationship between the treatment and outcome, and explain why.\n",
    "\n",
    "**Your response:** TODO\n",
    "\n",
    "2. Given the two variables you selected in the previous question, treatment, and outcome, draw a DAG with these four variables if this data were not collected from a randomized experiment. Give each node a variable name (e.g. $T$, $Y$, $C_1$, $C_2$) and indicate what each variable represents.\n",
    "\n",
    "\n",
    "TODO draw your DAG\n",
    "\n",
    "3. Draw the modified DAG from the previous question under the scenario where the treatment is randomized.\n",
    "\n",
    "\n",
    "TODO draw your DAG\n",
    "\n",
    ":::{admonition} Submission note\n",
    ":class: tip\n",
    "\n",
    "For this question, you can either hand-draw the graphs on paper and submit a photo or use an online tool of your choice. Please make sure the image is submitted as a separate file on Gradescope.\n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc15a16",
   "metadata": {},
   "source": [
    "### 3.3 Visualizing and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25635ca",
   "metadata": {},
   "source": [
    "Let's next ensure that the baseline characteristics are balanced between the treatment and control groups. Complete the `baseline_stats` function below to verify that the `bw`, `momage`, `nnhealth`, and `momwhite` characteristics are balanced and roughly match the values reported in Table 1 of Brooks-Gunn et al 1991.\n",
    "\n",
    ":::{tip}\n",
    "\n",
    "- It is possible to complete this operation in one line by using pandas `groupby()` + `agg()`\n",
    "\n",
    "- Since `momwhite` is coded as a binary variable, the mean will be the proportion of `momwhite = 1` in the sample.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_stats(df, covariate):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation of a covariate \n",
    "    for the treatment and control groups.\n",
    "    Assumes that the treatment indicator column is named `treat`.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to compute the baseline stats\n",
    "        covariate (str): the name of the covariate to compute the baseline stats\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: a grouped dataframe with the mean and standard deviation \n",
    "            of the covariate for the treatment and control groups\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    pass\n",
    "\n",
    "# display(baseline_stats(ihdp_raw, 'bw'))\n",
    "# display(baseline_stats(ihdp_raw, 'momage'))\n",
    "# display(baseline_stats(ihdp_raw, 'nnhealth'))\n",
    "# display(baseline_stats(ihdp_raw, 'momwhite'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b3f687",
   "metadata": {},
   "source": [
    "Beyond having similar mean and standard deviation, an implication of exchangeability is that the treatment and control groups should have a similar *distribution* of covariates. We can inspect this by plotting the (cumulative) distribution of the covariates for the treatment and control groups and visually inspecting whether the two distributions are similar.\n",
    "\n",
    "Let's verify this is the case for our continuous variables `bw`, `momage`, and `nnhealth`, using a distribution plot via `sns.kdeplot`. Specfically, complete the `plot_covariate_distribution` function below by generating a kde plot with:\n",
    "\n",
    "- the covariate on the x-axis\n",
    "- `treat` as the hue\n",
    "- `ihdp_df` as the data\n",
    "- `common_norm=False` to ensure that the y-axis is on the same scale for both the treatment and control groups\n",
    "- **optional**: `cumulative=True` to plot the cumulative distribution, to make the curves easier to compare\n",
    "\n",
    ":::{note}\n",
    "For the statistically curious: a natural hypothesis to test here is whether the two datasets come from the same distribution, which can be done using a [two-sample Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test).\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5882264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_covariate_distribution(df, covariate, title):\n",
    "    \"\"\"\n",
    "    Plots the (optionally cumulative) distribution of a covariate for the treatment and control groups.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to plot the covariate distribution\n",
    "        covariate (str): the name of the covariate to plot\n",
    "        title (str): the title of the plot\n",
    "    \n",
    "    Returns:\n",
    "        None, but shows the covariate cumulative distribution plot\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "#plot_covariate_distribution(ihdp_raw, 'bw', 'TODO title')\n",
    "#plot_covariate_distribution(ihdp_raw, 'momage', 'TODO title')\n",
    "#plot_covariate_distribution(ihdp_raw, 'nnhealth', 'TODO title')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9f06c",
   "metadata": {},
   "source": [
    "Our outcome is `iqsb.36`, which are the infant's IQ score at 36 months. However, there are some missing values in the `iqsb.36` column, so we need to drop the rows that do not have the outcome.\n",
    "\n",
    "Complete the `load_and_clean_ihdp_data` function below, and then run the cell to load the cleaned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14488579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_ihdp_data():\n",
    "    \"\"\"\n",
    "    Loads the IHDP dataset, selecting the columns of interest and dropping the rows that do not have the outcome.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the cleaned IHDP dataset with the following columns selected:\n",
    "            bw: birth weight in grams\n",
    "            momage: mother's age in years\n",
    "            iqsb.36: IQ score at 36 months\n",
    "            nnhealth: neonatal health index\n",
    "            momwhite: binary indicator for maternal ethnicity: 1 if white, 0 otherwise\n",
    "            treat: binary treatment assignment\n",
    "    \"\"\"\n",
    "    ihdp_df = pd.DataFrame()\n",
    "\n",
    "    # TODO your code here\n",
    "\n",
    "    assert ihdp_df.shape[0] == ihdp_df['iqsb.36'].notna().sum()\n",
    "    return ihdp_df\n",
    "\n",
    "ihdp_clean = load_and_clean_ihdp_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d02e9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e6962c",
   "metadata": {},
   "source": [
    "## 4. Bootstrap utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6c24b",
   "metadata": {},
   "source": [
    "Since we only have one real dataset, we cannot generate a distribution of the difference-in-means estimator over multiple experiments. However, we can use bootstrapping to generate a distribution of the difference-in-means estimator. \n",
    "\n",
    "As we saw in worksheet 3 and in class, bootstrapping is a powerful technique that allows us to generate a sampling distribution over *any* estimator by resampling the data with replacement. Copy your `bootstrap_dfs` function from Worksheet 3 below, which takes in a dataframe and returns a list of bootstrapped dataframes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43e12be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_dfs(df, n_bootstraps=5000):\n",
    "    \"\"\"\n",
    "    Bootstraps the dataframe `n_bootstraps` times.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to bootstrap\n",
    "        n_bootstraps (int): the number of bootstraps to generate\n",
    "\n",
    "    Returns:\n",
    "        list[pd.DataFrame]: a list of bootstrapped dataframes\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8547781",
   "metadata": {},
   "source": [
    "Next, we'll write a utility function to compute the bootstrapped confidence interval given a list of bootstrap values, similar to how we did in Worksheet 3.\n",
    "\n",
    ":::{note}\n",
    "\n",
    "This function takes in an alpha level of 0.05 by default, which corresponds to a 95% confidence interval. However, this implementation allows for any alpha level to be used, e.g. for 90% or 99% confidence intervals.\n",
    "\n",
    "Also note that while the `np.percentile` function takes in a percentage between 0 and 100, the `alpha` parameter is a proportion between 0 and 1. Be sure to convert to correct units!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3255ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(bootstrap_values, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Computes the confidence interval using the percentile method.\n",
    "\n",
    "    Args:\n",
    "        bootstrap_values (list[float]): the bootstrapped values\n",
    "        alpha (float): the significance level, defaults to 0.05\n",
    "\n",
    "    Returns:\n",
    "        list[float]: the confidence interval [lower, upper]\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f4ba9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8831dfbd",
   "metadata": {},
   "source": [
    "## 5 Estimation and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8b6cc",
   "metadata": {},
   "source": [
    "### 5.1 Difference-in-means estimation\n",
    "\n",
    "We'll now want to apply our difference-in-means estimators to the IHDP dataset. In order to use our stratified difference-in-means estimator, we need to binarize the continuous covariates we are analyzing. Complete the following `binarize_covariate` function, which creates a new binary covariate that is 1 if the covariate is greater than the cutpoint, and 0 otherwise.\n",
    "\n",
    "Then, apply the `binarize_covariate` function to the `momage` and `nnhealth` covariates:\n",
    "- using a cutpoint of 22 years for `momage`\n",
    "- using a cutpoint of 100 for `nnhealth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "656d8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_covariate(df, covariate, cutpoint):\n",
    "    \"\"\"\n",
    "    Creates a new binary covariate that is 1 if the covariate is greater than the cutpoint, and 0 otherwise.\n",
    "    Updates the dataframe in place with a new column named `{covariate}_bin`\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to update\n",
    "        covariate (str): the name of the covariate to binarize\n",
    "        cutpoint (float): the cutpoint to use for binarization\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the updated dataframe with the new binary covariate\n",
    "    \"\"\"\n",
    "    # TODO your code here\n",
    "    return df\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, 5]})\n",
    "assert binarize_covariate(df, 'A', 2.5).equals(pd.DataFrame({'A': [1, 2, 3, 4, 5], 'A_bin': [0, 0, 1, 1, 1]}))\n",
    "\n",
    "# TODO call binarize_covariate on the `momage` and `nnhealth` covariates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a94e1",
   "metadata": {},
   "source": [
    "Finally, let's compute our results. For the following difference-in-means estimators:\n",
    " - unstratified difference-in-means estimator for the `iqsb.36` outcome\n",
    " - stratified difference-in-means estimator for the `iqsb.36` outcome, binarized by `momage`\n",
    " - stratified difference-in-means estimator for the `iqsb.36` outcome, binarized by `nnhealth`\n",
    " - stratified difference-in-means estimator for the `iqsb.36` outcome, binarized by `momwhite`\n",
    "\n",
    "Compute and report the following in the markdown table below (up to two decimal places):\n",
    "- the estimate for the difference-in-means estimator, **using the cleaned dataset** (not a bootstrap sample).\n",
    "- the bootstrapped 95% confidence interval (CI) for the difference-in-means estimator\n",
    "- the length of the confidence interval, which is the difference between the upper and lower bounds of the confidence interval\n",
    "\n",
    ":::{tip}\n",
    "See the comments in the code cell below for guidance on how you might want to structure your analysis, and feel free to create helper functions to organize your code. You do not have to follow the comments exactly, they are just a suggestion!\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae892cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO get point estimates using the cleaned dataset\n",
    "point_estimates = {\n",
    "    \"unstratified\": 0,\n",
    "    \"stratified_nnhealth\": 0,\n",
    "    \"stratified_momage\": 0,\n",
    "    \"stratified_momwhite\": 0\n",
    "}\n",
    "\n",
    "# TODO generate bootstrap dataframes\n",
    "\n",
    "# TODO create a structure to store difference-in-means results\n",
    "\n",
    "# TODO compute difference-in-means for each bootstrapped dataframe\n",
    "\n",
    "# TODO report the results for each estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deedd693",
   "metadata": {},
   "source": [
    "| Estimator | Effect | 95% CI | Length of CI |\n",
    "| --- | --- | --- | --- |\n",
    "| Difference-in-means | TODO | TODO | TODO |\n",
    "| Difference-in-means stratified by `nnhealth_bin` | TODO | TODO | TODO |\n",
    "| Difference-in-means stratified by `momage_bin` | TODO | TODO | TODO |\n",
    "| Difference-in-means stratified by `momwhite` | TODO | TODO | TODO |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006021d3",
   "metadata": {},
   "source": [
    "### 5.2 Interpretation\n",
    "\n",
    "Finally, let's interpret the results.\n",
    "\n",
    "1. Do any of the estimators appear to disagree with the others in terms of the estimate? Which estimator produces the shortest confidence interval?\n",
    "\n",
    "2. Based on your analysis, what conclusions can you draw about the average treatment effect of the intervention? Does it improve or worsen the outcome? \n",
    "\n",
    "3. Discuss any ethical/design considerations of the experimental setup you noticed (~1-2 paragraphs). You can refer back to our discussion of these challenges from class and the study design described in the reading. Some questions you could consider:\n",
    "\n",
    "- At the time the study was designed, do you think there was genuine uncertainty about the effectiveness of the intervention? Why might researchers have considered the intervention promising but unproven?\n",
    "- What do you notice about how infants were recruited into the study? Are they representative of the overall U.S. population of underweight newborns?\n",
    "- Is the selected outcome appropriate for evaluating the intervention's impact? What are some other outcomes that could be used to evaluate the intervention?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637cd1f",
   "metadata": {},
   "source": [
    "**TODO** your responses here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885bb11b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67596ede",
   "metadata": {},
   "source": [
    "## 6. Reflection\n",
    "\n",
    "1. How much time did you spend on this assignment?\n",
    "\n",
    "2. Were there any parts of the assignment that you found particularly challenging?\n",
    "\n",
    "3. What is one thing you have a better understanding of after completing this assignment and going through the class content?\n",
    "\n",
    "4. Do you have any follow-up questions about concepts that you'd like to explore further?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f27fe3",
   "metadata": {},
   "source": [
    "**TODO** your responses here:\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ddd303",
   "metadata": {},
   "source": [
    "## 7. Optional extensions\n",
    "\n",
    "If you'd like, here are some optional extensions you can explore and implement:\n",
    "\n",
    "- Our stratified estimator currently only works for stratifying on binary variables. A natural extension would be to modify our `diff_in_means_stratified` function to work for multiple strata.\n",
    "- Once our stratified difference in means estimate is extended to support multiple strata, we can explore the trade-off between using more or fewer strata for continuous variables, and seeing how this affects the variance of our estimator. This can be done by using the `pd.cut` function to bin the covariate into a discrete number of bins.\n",
    "- Another benefit of a randomized experiment is that we can use them to study multiple outcomes. Brooks-Gunn et al. 1991 mention that the IQ score only provide a global estimate of cognitive function, and so also conduct analysis on the Peabody Picture Vocabulary Test (PPVT) which assesses vocabulary. We can follow the causal roadmap again to analyze this outcome, represented as the `ppvt.imp` column in the IHDP dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
