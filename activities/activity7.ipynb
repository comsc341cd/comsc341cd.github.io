{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(activity7)=\n",
    "# Activity 7: Positivity in Observational Studies\n",
    "\n",
    "**2025-02-27**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the data\n",
    "learning_df = pd.read_csv(\"~/COMSC-341CD/data/learning_mindset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This selected portion of the National Study of Learning Mindsets dataset is not truly randomized, so we'll need to adjust for confounding.\n",
    "\n",
    "The columns we will look at are:\n",
    "\n",
    "- `intervention`: whether the student received the intervention (1) or not (0)\n",
    "- `success_expect`: stud\n",
    "ent Likert scale response to a fixed mindset survey question prior to the intervention: \"You have a certain amount of intelligence, and you really canâ€™t do much to change it\" (1, strongly disagree; 7, strongly agree)\n",
    "- `frst_in_family`: whether the student would be the first in their family to attend college (1) or not (0)\n",
    "- `gender`: student's self-reported gender\n",
    "- `school_urbanicity`: categorical variable corresponding to the urbanicity of the school the student attends, e.g. urban, suburban, rural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariates = ['success_expect', 'frst_in_family']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first consider the variables in `covariates` as `success_expect` and `frst_in_family`. These seem to be reasonable potential confounders to control for. If we take the same strategy as we have done with the kidney stone dataset, we'll need to bin on the confounders and compute treatment effects for each bin.\n",
    "\n",
    "However, as we've seen today, we also need to be careful about positivity violations. First, let's compute the total number of bins we need to create if we want to control for these two covariates.\n",
    "\n",
    "We can do this by using [pd.Series.nunique](https://pandas.pydata.org/docs/reference/api/pandas.Series.nunique.html) to get the number of unique values for each covariate and then multiplying them together. This is like taking a cross product over the all possible values of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO calculate the total number of bins \n",
    "total_bins = 0\n",
    "\n",
    "print(f\"Total number of bins: {total_bins}\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's see if there are any positivity violations. We can do this by grouping over the covariiats plus the intervention, and then counting the number of unique groups are actually present in the data.\n",
    "\n",
    "To generate the per-bin counts, we perform a `groupby(all_cols, as_index=False)` over the intervention and all combinations of the other columns, and the check the `ngroups` attribute of the resulting groupby object. How many groups are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the intervention column and the two covariates\n",
    "all_cols = []\n",
    "group_count = learning_df.groupby(all_cols, as_index=False).ngroups\n",
    "\n",
    "print(f\"Number actual groups among the bins for {all_cols}: {group_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we need each bin to have both control and treatment units in order to have a valid comparison, the total number of groups should be equal to **2 times the total number of bins possible** for there to be no positivity violations.\n",
    "\n",
    "Does the number of rows you found in part 2 match this?\n",
    "\n",
    "**Your response**: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "Ideally we'd like to control for as many confounders as possible, let's now add `gender` and `school_urbanicity` to our list of covariates, making a total of 4 confounders.\n",
    "\n",
    "Repeat the analysis above with the new set of covariates. Do we see positivity violations with the new set of covariates?\n",
    "\n",
    "**Your response**: TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO your code here for part 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional extra**: if we actually want to see the bins that are missing, we can generate a [pivot_table](https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html) of the counts, and then identify the bins that are missing in either the control or treatment group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = learning_df.groupby(all_cols, as_index=False).size()\n",
    "\n",
    "# Create a pivot table to show counts by intervention and bins\n",
    "bin_pivot = pd.pivot_table(\n",
    "    count_df, \n",
    "    index=['success_expect', 'gender', 'frst_in_family', 'school_urbanicity'],\n",
    "    columns=['intervention'],\n",
    "    values='intervention',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Display information about the pivot table\n",
    "print(\"Bins with no control units:\")\n",
    "display(bin_pivot[bin_pivot[0] == 0])\n",
    "\n",
    "print(\"Bins with no treatment units:\")\n",
    "display(bin_pivot[bin_pivot[1] == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- Yeager, D. S. et al. (2019). A national experiment reveals where a growth mindset improves achievement. Nature.\n",
    "- Athey, S., & Wager, S. (2019). Estimating treatment effects with causal forests: An application. Observational studies.\n",
    "- Facure, M. (2023). Causal Inference for the Brave and the True."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
